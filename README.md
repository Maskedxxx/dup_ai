# Contractor Analysis API

API для анализа данных о подрядчиках, рисках проектов, ошибках и бизнес-процессах с использованием LLM.

## Архитектура

Приложение построено по принципам чистой архитектуры (Clean Architecture):

```
┌─────────────────────────────────────────────────────────────┐
│                        API Layer                            │
│                   (FastAPI endpoints)                       │
├─────────────────────────────────────────────────────────────┤
│                    Pipeline Layer                           │
│              (Orchestration & Flow)                         │
├─────────────────────────────────────────────────────────────┤
│                    Service Layer                            │
│        (Business Logic & Processing)                        │
├─────────────────────────────────────────────────────────────┤
│                    Domain Layer                             │
│              (Models & Business Rules)                      │
├─────────────────────────────────────────────────────────────┤
│                   Adapter Layer                             │
│           (External Services & Data)                        │
└─────────────────────────────────────────────────────────────┘
```

## Основные компоненты

### 1. API Layer (`app/api/`)
- **endpoints.py** - REST API эндпоинты
- **schemas.py** - Pydantic модели для валидации запросов/ответов

### 2. Pipeline Layer (`app/pipelines/`)
- **base.py** - Базовый класс для всех пайплайнов с блочным логированием
- **contractors_pipeline.py** - Обработка запросов о подрядчиках
- **risks_pipeline.py** - Обработка запросов о рисках
- **errors_pipeline.py** - Обработка запросов об ошибках проектов  
- **processes_pipeline.py** - Обработка запросов о бизнес-процессах

### 3. Service Layer (`app/services/`)
Каждый тип данных имеет 3 сервиса:
- **Normalization** - нормализация данных из Excel
- **Classifier** - классификация запросов с помощью LLM (с динамическими Literal типами)
- **AnswerGenerator** - генерация ответов с помощью LLM

### 4. Domain Layer (`app/domain/`)
- **models/** - доменные модели (Contractor, Risk, Error, Process)
- **enums.py** - перечисления (ButtonType, RiskCategory)

### 5. Adapter Layer (`app/adapters/`)
- **excel_loader.py** - загрузка данных из Excel
- **llm_client.py** - интеграция с LLM (Ollama)

## Поток данных

1. **Запрос от клиента** → API endpoint
2. **Выбор пайплайна** по типу кнопки (contractors/risks/errors/processes)
3. **[ШАГ 1] Загрузка данных** из Excel файла
4. **[ШАГ 2] Нормализация** - очистка и стандартизация данных
5. **[ШАГ 3] Предварительная обработка** - фильтрация по категориям
6. **[ШАГ 4] Загрузка элементов** для классификации
7. **[ШАГ 5] Классификация** - определение релевантных элементов через LLM с Literal типами
8. **[ШАГ 6] Фильтрация** - отбор данных по результатам классификации
9. **[ШАГ 7] Преобразование** - создание доменных моделей
10. **[ШАГ 8] Генерация ответа** - создание ответа через LLM
11. **Возврат ответа** клиенту

## Быстрый старт

### 1. Установка зависимостей
```bash
pip install -r requirements.txt
```

### 2. Настройка конфигурации
```bash
cp .env.example .env
# Отредактируйте .env файл
```

### 3. Подготовка данных
Поместите Excel файлы в директорию `data/`:
- `contractors.xlsx` - данные о подрядчиках
- `riski.xlsx` - данные о рисках проектов
- `errors.xlsx` - данные об ошибках
- `bpmn_processes.xlsx` - данные о бизнес-процессах

### 4. Запуск приложения
```bash
uvicorn app.main:app --reload
```

### 5. Проверка работы
```bash
curl http://localhost:8080/v1/health 
```

## API Документация

### POST /v1/ask
Основной эндпоинт для обработки запросов.

**Request:**
```json
{
  "question": "Найди подрядчиков для строительства дорог",
  "button": "contractors",
  "risk_category": null  // только для button="risks"
}
```

**Response:**
```json
{
  "text": "Сгенерированный ответ от LLM",
  "query": "Исходный запрос",
  "total_found": 5,
  "items": [...],  // Список найденных элементов
  "meta": {},
  "category": null
}
```

### Типы кнопок:
- `contractors` - поиск подрядчиков
- `risks` - анализ рисков проектов
- `errors` - анализ ошибок проектов
- `processes` - поиск бизнес-процессов

### Категории рисков:
- `niokr` - НИОКР проекты
- `product_project` - продуктовые проекты
- `manufacturing` - производственные проекты

## Конфигурация

### Единая конфигурация классификации

Система использует единую конфигурацию `ClassificationConfig` для управления логикой классификации всех типов сущностей. Это позволяет легко настраивать, какие колонки использовать для фильтрации данных.

#### Структура конфигурации (`app/config.py`)

```python
class ClassificationConfig:
    # Настройки для подрядчиков
    CONTRACTOR = {
        "column_name": "work_types",        # Колонка для классификации
        "item_type": "вид работ",           # Тип элемента для LLM
        "description": "Классификация по видам работ подрядчиков"
    }
    
    # Настройки для рисков
    RISK = {
        "column_name": "project_name", 
        "item_type": "проект",
        "description": "Классификация рисков по названиям проектов"
    }
    
    # Настройки для ошибок
    ERROR = {
        "column_name": "project_name",
        "item_type": "проект", 
        "description": "Классификация ошибок по проектам"
    }
    
    # Настройки для процессов
    PROCESS = {
        "column_name": "process_name",
        "item_type": "процесс",
        "description": "Классификация по бизнес-процессам"
    }
```

#### Как изменить конфигурацию

Для изменения логики классификации просто обновите соответствующий раздел:

```python
# Изменить колонку для подрядчиков с "work_types" на "service_categories"
ClassificationConfig.CONTRACTOR["column_name"] = "service_categories"
ClassificationConfig.CONTRACTOR["item_type"] = "категория услуг"

# Изменить колонку для рисков с "project_name" на "risk_category"  
ClassificationConfig.RISK["column_name"] = "risk_category"
ClassificationConfig.RISK["item_type"] = "категория риска"
```

#### Принцип работы

1. **LLM классификация**: Система загружает уникальные значения из указанной колонки
2. **Динамические Literal типы**: Создаются Pydantic модели с точным списком доступных вариантов  
3. **Фильтрация**: Данные фильтруются по выбранному LLM элементу
4. **Генерация ответа**: LLM создает ответ на основе отфильтрованных данных

### Переменные окружения (.env)

```env
# Приложение
APP_NAME=Contractor Analysis API
DEBUG=true  # true - DEBUG режим, false - PROD режим
HOST=0.0.0.0
PORT=8080

# LLM настройки
LLM_OLLAMA_BASE_URL=http://localhost:11434/v1
LLM_OLLAMA_MODEL=llama3.1:8b-instruct-fp16

# Пути к данным
CONTRACTOR_DATA_FILE_PATH=./data/contractors.xlsx
RISK_DATA_FILE_PATH=./data/riski.xlsx
ERROR_DATA_FILE_PATH=./data/errors.xlsx
PROCESS_DATA_FILE_PATH=./data/bpmn_processes.xlsx

# Лимиты
CONTRACTOR_MAX_RESULTS=20
RISK_MAX_RESULTS=20
```

## Логирование

### Блочная система логирования

Приложение использует блочную систему логирования с уникальными Pipeline ID для отслеживания каждого запроса:

- **Единый файл логов**: `LOGS/dup_ai.log` для всего приложения
- **Уникальные Pipeline ID**: каждый запрос получает ID (например: `a1b2c3d4`)
- **Структурированные блоки**: начало/конец пайплайна четко выделены

### Режимы логирования

#### DEBUG режим (`DEBUG=true`)
- Полная детализация всех 8 шагов пайплайна
- Логирование промптов и ответов LLM
- Детальная информация о нормализации данных
- Информация о загрузке файлов

#### PROD режим (`DEBUG=false`)
- Только статусы выполнения шагов
- Минимальная детализация
- Оптимизация для продакшена

### Пример структуры логов

**DEBUG режим:**
```
================================================================================
[БЛОК НАЧАЛО] Pipeline ID: a1b2c3d4 | Режим: DEBUG
[ЗАПРОС] Кнопка: contractors | Вопрос: 'найти подрядчиков для дорог'
================================================================================
[ШАГ 1 ОК] Загрузка данных: Файл загружен: ./data/contractors.xlsx (156 строк)
[a1b2c3d4] Колонки в файле: ['Наименование_КА', 'Виды_работ', ...]
[ШАГ 2 ОК] Нормализация данных: Нормализовано 156 строк
[a1b2c3d4] Переименованы колонки: {'Наименование_КА': 'name', ...}
[ШАГ 3 ОК] Предварительная обработка: Обработано 156 строк
[ШАГ 4 ОК] Загрузка элементов: Загружено 25 уникальных элементов
[ШАГ 5 ОК] Классификация: Выбран элемент 'дорожные работы'
[a1b2c3d4] === CLASSIFICATION ПРОМПТ ===
[a1b2c3d4] SYSTEM PROMPT: Ты эксперт по классификации...
[ШАГ 6 ОК] Фильтрация данных: Найдено 8 подходящих записей
[ШАГ 7 ОК] Преобразование в модели: Создано 8 моделей
[ШАГ 8 ОК] Генерация ответа: Ответ сгенерирован (1234 символов)
[БЛОК КОНЕЦ] Pipeline ID: a1b2c3d4 | Успешно завершен за 3.45с
================================================================================
```

**PROD режим:**
```
================================================================================
[БЛОК НАЧАЛО] Pipeline ID: a1b2c3d4 | Режим: PROD
[ЗАПРОС] Кнопка: contractors | Вопрос: 'найти подрядчиков для дорог'
================================================================================
[ШАГ 1 ОК] Загрузка данных
[ШАГ 2 ОК] Нормализация данных
[ШАГ 3 ОК] Предварительная обработка
[ШАГ 4 ОК] Загрузка элементов
[ШАГ 5 ОК] Классификация
[ШАГ 6 ОК] Фильтрация данных
[ШАГ 7 ОК] Преобразование в модели
[ШАГ 8 ОК] Генерация ответа
[БЛОК КОНЕЦ] Pipeline ID: a1b2c3d4 | Успешно завершен за 3.45с
================================================================================
```

### Настройка логгера в коде

```python
from app.utils.logging import get_pipeline_logger

# Создание логгера пайплайна
pipeline_logger = get_pipeline_logger(__name__)

# Начало блока
pipeline_id = pipeline_logger.start_pipeline_block("contractors", "вопрос")

# Логирование шагов
pipeline_logger.log_step_ok(1, "Загрузка данных", "детали")
pipeline_logger.log_detail("Детальная информация")

# Завершение блока
pipeline_logger.end_pipeline_block(success=True)
```

## Отладка и мониторинг

### Поиск и анализ логов

```bash
# Мониторинг в реальном времени
tail -f LOGS/dup_ai.log

# Поиск по Pipeline ID
grep "a1b2c3d4" LOGS/dup_ai.log

# Только шаги пайплайнов
grep "\[ШАГ" LOGS/dup_ai.log

# Поиск ошибок
grep "ОШИБКА\|ERROR" LOGS/dup_ai.log

# Просмотр промптов LLM (DEBUG режим)
grep -A 20 "SYSTEM PROMPT" LOGS/dup_ai.log
```

### Типовые команды для отладки

```bash
# Проверка состояния приложения
curl http://localhost:8080/v1/health

# Проверка LLM
curl http://localhost:11434/api/tags

# Тестовый запрос
curl -X POST "http://localhost:8080/v1/ask" \
     -H "Content-Type: application/json" \
     -d '{"question": "тест", "button": "contractors"}'

# Переключение в DEBUG режим
# Измените DEBUG=true в .env и перезапустите приложение
```

## Решение проблем

### LLM не отвечает
- Проверьте доступность Ollama: `curl http://localhost:11434/api/tags`
- Убедитесь, что модель скачана: `ollama list`

### Ошибки загрузки данных
- Проверьте пути к файлам в `.env`
- Убедитесь, что Excel файлы имеют правильную структуру
- Посмотрите логи загрузки в DEBUG режиме

### Проблемы с классификацией
- В DEBUG режиме проверьте промпты классификации в логах
- Убедитесь, что в данных есть уникальные элементы для классификации
- Проверьте, что LLM возвращает корректный JSON

### Анализ производительности
- Время выполнения каждого пайплайна указано в логах
- Проверьте время ответа LLM в детальных логах
- Используйте Pipeline ID для отслеживания конкретных запросов

## Тестирование

### Универсальный тестер пайплайнов

Для тестирования всех пайплайнов с новой конфигурацией классификации используйте `test_universal_pipeline.py`:

#### Интерактивный режим
```bash
python test_universal_pipeline.py
```

Интерактивный режим позволяет:
- Выбрать тип кнопки (contractors/risks/errors/processes)
- Ввести произвольный вопрос
- Указать категорию риска (для кнопки risks)
- Увидеть как работает новая конфигурация классификации

#### Режим с аргументами
```bash
# Тест подрядчиков
python test_universal_pipeline.py contractors "Найти подрядчика для строительства"

# Тест рисков с категорией
python test_universal_pipeline.py risks "Основные риски производства" manufacturing

# Тест ошибок
python test_universal_pipeline.py errors "Ошибки в проекте разработки ПО"

# Тест процессов
python test_universal_pipeline.py processes "Процесс управления проектами"
```

#### Что показывает тестер
- Конфигурацию классификации (какая колонка используется)
- Результаты каждого шага пайплайна
- Найденные элементы с оценками релевантности
- Сгенерированный ответ LLM
- Детальные логи обработки

#### Справка
```bash
python test_universal_pipeline.py --help
```

## Примеры использования

### Python клиент
```python
import requests

response = requests.post(
    "http://localhost:8080/v1/ask",
    json={
        "question": "Какие подрядчики занимаются дорожным строительством?",
        "button": "contractors"
    }
)

data = response.json()
print(f"Найдено: {data['total_found']} подрядчиков")
print(data['text'])
```

### cURL
```bash
curl -X POST "http://localhost:8080/v1/ask" \
     -H "Content-Type: application/json" \
     -d '{
       "question": "Риски для НИОКР проектов",
       "button": "risks",
       "risk_category": "niokr"
     }'
```

## Архитектурные решения

1. **Базовые классы** - минимизация дублирования кода
2. **Dependency Injection** - управление зависимостями через Container
3. **Фабричный паттерн** - создание пайплайнов
4. **Чистая архитектура** - независимость слоев
5. **Pydantic модели** - валидация данных
6. **Async/await** - асинхронная обработка запросов
7. **Блочное логирование** - отслеживание запросов с уникальными ID
8. **Динамические Literal типы** - точная классификация без опечаток
9. **Единая конфигурация классификации** - гибкая настройка колонок для фильтрации

## Контакты

При возникновении вопросов обращайтесь к автору проекта.