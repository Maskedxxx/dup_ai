# Шаг 6.5: Умная фильтрация (внутри контура пайплайна)

## Вход
- question: текст вопроса пользователя.
- df: DataFrame после базовой фильтрации по классификации (результат шага 6).
- button_type: тип пайплайна (ButtonType.CONTRACTORS/RISKS/ERRORS/PROCESSES).
- relevance_scores: базовые оценки релевантности из предыдущего шага.

## Что происходит внутри
1) Определение стратегии фильтрации
- По типу кнопки выбирается стратегия из `SmartFilteringSettings.strategy`:
  - `contractors`: "none" — умная фильтрация отключена
  - `risks`: "keybert" — используется семантический поиск по ключевым словам
  - `errors`: "none" — умная фильтрация отключена
  - `processes`: "none" — умная фильтрация отключена
- Где: `ToolExecutor.apply_smart_filtering()` → `smart_filtering_settings.strategy.get(button_type.value)`.

2) Выполнение стратегии "none"
- Если стратегия = "none" → возвращаются исходные данные без изменений.
- Логируется информация о пропуске умной фильтрации.
- Где: `ToolExecutor.apply_smart_filtering()` (early return).

3) Выполнение стратегии "keybert" (только для рисков)
- Извлекаются ключевые слова из вопроса через KeyBERT:
  - Вызов: `KeyBERTService.extract_keywords(question, top_n=7, keyphrase_ngram_range=(1, 1))`
  - Результат: список строк-ключевых слов, ранжированных по релевантности
- Определяется инструмент из `strategy_tool_map`: "keybert" → "search_by_keywords"
- Получается инструмент из `ToolRegistry.get_tool("search_by_keywords")`
- Где: `ToolExecutor._execute_keybert_strategy()`.

4) Выполнение инструмента KeywordSearchTool
- Подготовка аргументов:
  - `df`: отфильтрованный DataFrame
  - `keywords`: ключевые слова от KeyBERT
  - `top_n`: количество результатов (по умолчанию 5)
- Лемматизация ключевых слов и текста в колонке `risk_text` через pymorphy3
- Расчет релевантности каждой записи к ключевым словам
- Фильтрация записей с релевантностью > 0 и выбор топ-N
- Где: `KeywordSearchTool.execute()` → `app/tools/implementations/_shared/keyword_search_tool.py`.

5) Лемматизация и поиск (детали KeywordSearchTool)
- Нормализация текста: приведение к нижнему регистру, удаление знаков препинания
- Лемматизация каждого слова: `morph.parse(word)[0].normal_form`
- Создание временной колонки `lemmatized_risk_text` в DataFrame
- Поиск совпадений лемматизированных ключевых слов в лемматизированном тексте
- Расчет оценки релевантности через `calculate_relevance_score()`
- Где: `KeywordSearchTool._lemmatize_text()`, `KeywordSearchTool.execute()`.

6) Возврат результатов
- Если умная фильтрация нашла релевантные записи → возвращается топ-N с новыми оценками релевантности
- Если совпадений не найдено → возвращаются исходные данные из шага 6
- Логируется количество найденных записей и применённая стратегия
- Где: `ToolExecutor.apply_smart_filtering()` (возврат в BasePipeline).

7) Логирование процесса
- Стратегия фильтрации и выбранный инструмент
- Ключевые слова, извлечённые KeyBERT
- Лемматизированные ключевые слова после обработки
- Количество найденных совпадений и итоговых результатов
- В debug-режиме: подробности расчёта релевантности для каждой записи

## Выход
- final_df: DataFrame с умно отфильтрованными записями (или исходный, если стратегия "none")
- final_scores: Dict[int, float] с обновлёнными оценками релевантности (индекс → оценка)

## Ошибки и поведение
- Любая ошибка в KeyBERT/инструментах → логируется, возвращаются исходные данные
- Пустой список ключевых слов → предупреждение, возвращаются исходные данные
- Отсутствие колонки `risk_text` → критическая ошибка, возвращается пустой DataFrame
- Незарегистрированный инструмент → ошибка, возвращаются исходные данные

## Где в коде
- Оркестрация шага: `app/pipelines/base.py` ("ШАГ 6.5: Умная фильтрация")
- Главный исполнитель: `app/tools/tool_executor.py` (ToolExecutor.apply_smart_filtering)
- Конфигурация стратегий: `app/config.py` (SmartFilteringSettings)
- Извлечение ключевых слов: `app/services/keybert_service.py` (KeyBERTService)
- Реестр инструментов: `app/tools/registry.py` (ToolRegistry)
- Поиск по ключевым словам: `app/tools/implementations/_shared/keyword_search_tool.py`
- Расчёт релевантности: `app/tools/base_tool.py` (calculate_relevance_score)

## Конфигурация (app/config.py)
```python
# Стратегии для каждого типа пайплайна
strategy = {
    "contractors": "none",      # Без умной фильтрации
    "risks": "keybert",        # KeyBERT + поиск по ключевым словам
    "errors": "none",          # Без умной фильтрации  
    "processes": "none",       # Без умной фильтрации
}

# Маппинг стратегий на инструменты
strategy_tool_map = {
    "keybert": "search_by_keywords",
}
```

## Почему так
- **Условность**: только пайплайн рисков нуждается в семантическом поиске из-за сложности и объёма данных
- **Расширяемость**: легко добавить новые стратегии ("llm", "both") и инструменты через конфигурацию
- **Отказоустойчивость**: ошибки умной фильтрации не ломают пайплайн — используются данные базовой фильтрации
- **Производительность**: pymorphy3 инициализируется один раз, лемматизация кэшируется в DataFrame
- **Прозрачность**: все ключевые операции детально логируются для отладки семантического поиска

## Будущие стратегии (заглушки)
- **"llm"**: LLM выберет инструмент на основе схем и вопроса пользователя
- **"both"**: комбинация KeyBERT и LLM-выбора инструментов с объединением результатов